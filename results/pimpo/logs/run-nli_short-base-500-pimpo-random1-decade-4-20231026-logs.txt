Terminal execution:  True   (sys.argv[0]:  analysis-transformers-run.py )
Arguments passed via the terminal:

pimpo    dataset
500    sample_size_train
None    sample_size_corpus
20000    sample_size_no_topic
None    sample_size_test
nli_short    method
MoritzLaurer/deberta-v3-base-zeroshot-v1    model
transformer    vectorizer
20231026    study_date
pimpo-simple    task
4    n_run
6    n_random_runs_total
random1    group_sample
True    save_outputs
decade    group_column
448    max_length
Iteration number:  3
All random seeds:  [7270  860 5390 5191 5734 6265]
Random seed for this run:  5191
deberta-v3-base-zeroshot-v
Dataset:  pimpo 

Overall label distribution per group member:
 label_text  no_topic  supportive  sceptical  neutral
decade                                              
1990            4432         271        147       72
2000           48640        2864       1114      448
2010           26928        1455        539      258
Group selected: ['2010']  for seed 5191
Sample that might be imbalanced: df_train.label_text.value_counts:
 no_topic      300
neutral        66
sceptical      66
supportive     66
Name: label_text, dtype: int64

FINAL DF_TRAIN SAMPLE (BALANCED) for group \b2010\b:
df_train.label_text.value_counts:
 no_topic      300
neutral        66
sceptical      66
supportive     66
Name: label_text, dtype: int64

For NLI: Augmenting data by adding random not_entail examples to the train set from other classes within the train set.
Length of df_train before this step is: 498.

Max augmentation can be: len(df_train) * 2 = 996. Can also be lower, if there are more entail examples than not-entail for a majority class
For NLI:  not_entail training examples were added, which leads to an augmented training dataset of length 894.
Number of hypotheses/classes:  4 

For normal test, N classifications necessary: 6792
For NLI test, N classifications necessary: 27168

Device: cuda
Map:   0%|          | 0/894 [00:00<?, ? examples/s]                                                   Map:   0%|          | 0/27168 [00:00<?, ? examples/s]Map:  15%|█▍        | 4000/27168 [00:00<00:00, 29622.10 examples/s]Map:  29%|██▉       | 8000/27168 [00:00<00:00, 30610.25 examples/s]Map:  44%|████▍     | 12000/27168 [00:00<00:00, 31284.71 examples/s]Map:  59%|█████▉    | 16000/27168 [00:00<00:00, 25309.90 examples/s]Map:  74%|███████▎  | 20000/27168 [00:00<00:00, 27471.59 examples/s]Map:  88%|████████▊ | 24000/27168 [00:00<00:00, 28947.04 examples/s]Map: 100%|██████████| 27168/27168 [00:00<00:00, 28783.15 examples/s]                                                                      0%|          | 0/196 [00:00<?, ?it/s]You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  1%|          | 1/196 [00:00<00:24,  8.04it/s]  1%|          | 2/196 [00:00<00:22,  8.60it/s]  2%|▏         | 4/196 [00:00<00:17, 10.83it/s]  3%|▎         | 6/196 [00:00<00:17, 11.04it/s]  4%|▍         | 8/196 [00:00<00:16, 11.11it/s]  5%|▌         | 10/196 [00:00<00:16, 11.19it/s]  6%|▌         | 12/196 [00:01<00:16, 11.10it/s]  7%|▋         | 14/196 [00:01<00:16, 11.28it/s]  8%|▊         | 16/196 [00:01<00:15, 11.29it/s]  9%|▉         | 18/196 [00:01<00:15, 11.34it/s] 10%|█         | 20/196 [00:01<00:15, 11.42it/s] 11%|█         | 22/196 [00:01<00:15, 11.44it/s] 12%|█▏        | 24/196 [00:02<00:15, 11.45it/s] 13%|█▎        | 26/196 [00:02<00:14, 11.44it/s] 14%|█▍        | 28/196 [00:02<00:14, 11.49it/s]                                                 14%|█▍        | 28/196 [00:02<00:14, 11.49it/s] 15%|█▌        | 30/196 [00:02<00:14, 11.40it/s] 16%|█▋        | 32/196 [00:02<00:14, 11.42it/s] 17%|█▋        | 34/196 [00:03<00:14, 11.38it/s] 18%|█▊        | 36/196 [00:03<00:14, 11.39it/s] 19%|█▉        | 38/196 [00:03<00:13, 11.50it/s] 20%|██        | 40/196 [00:03<00:13, 11.58it/s] 21%|██▏       | 42/196 [00:03<00:13, 11.49it/s] 22%|██▏       | 44/196 [00:03<00:13, 11.50it/s] 23%|██▎       | 46/196 [00:04<00:12, 11.57it/s] 24%|██▍       | 48/196 [00:04<00:12, 11.62it/s] 26%|██▌       | 50/196 [00:04<00:12, 11.52it/s] 27%|██▋       | 52/196 [00:04<00:12, 11.47it/s] 28%|██▊       | 54/196 [00:04<00:12, 11.53it/s] 29%|██▊       | 56/196 [00:04<00:12, 11.57it/s]                                                 29%|██▊       | 56/196 [00:04<00:12, 11.57it/s] 30%|██▉       | 58/196 [00:05<00:12, 11.47it/s] 31%|███       | 60/196 [00:05<00:11, 11.52it/s] 32%|███▏      | 62/196 [00:05<00:11, 11.56it/s] 33%|███▎      | 64/196 [00:05<00:11, 11.42it/s] 34%|███▎      | 66/196 [00:05<00:11, 11.42it/s] 35%|███▍      | 68/196 [00:05<00:11, 11.49it/s] 36%|███▌      | 70/196 [00:06<00:11, 11.45it/s] 37%|███▋      | 72/196 [00:06<00:10, 11.53it/s] 38%|███▊      | 74/196 [00:06<00:10, 11.56it/s] 39%|███▉      | 76/196 [00:06<00:10, 11.51it/s] 40%|███▉      | 78/196 [00:06<00:10, 11.58it/s] 41%|████      | 80/196 [00:07<00:10, 11.55it/s] 42%|████▏     | 82/196 [00:07<00:09, 11.44it/s] 43%|████▎     | 84/196 [00:07<00:09, 11.53it/s]                                                 43%|████▎     | 84/196 [00:07<00:09, 11.53it/s] 44%|████▍     | 86/196 [00:07<00:09, 11.54it/s] 45%|████▍     | 88/196 [00:07<00:09, 11.60it/s] 46%|████▌     | 90/196 [00:07<00:09, 11.61it/s] 47%|████▋     | 92/196 [00:08<00:09, 11.53it/s] 48%|████▊     | 94/196 [00:08<00:08, 11.48it/s] 49%|████▉     | 96/196 [00:08<00:08, 11.53it/s] 50%|█████     | 98/196 [00:08<00:08, 11.51it/s] 51%|█████     | 100/196 [00:08<00:08, 11.58it/s] 52%|█████▏    | 102/196 [00:08<00:08, 11.47it/s] 53%|█████▎    | 104/196 [00:09<00:08, 11.47it/s] 54%|█████▍    | 106/196 [00:09<00:07, 11.46it/s] 55%|█████▌    | 108/196 [00:09<00:07, 11.39it/s] 56%|█████▌    | 110/196 [00:09<00:07, 11.36it/s] 57%|█████▋    | 112/196 [00:09<00:07, 11.55it/s]                                                  57%|█████▋    | 112/196 [00:09<00:07, 11.55it/s] 58%|█████▊    | 114/196 [00:09<00:07, 11.47it/s] 59%|█████▉    | 116/196 [00:10<00:06, 11.52it/s] 60%|██████    | 118/196 [00:10<00:06, 11.58it/s] 61%|██████    | 120/196 [00:10<00:06, 11.62it/s] 62%|██████▏   | 122/196 [00:10<00:06, 11.51it/s] 63%|██████▎   | 124/196 [00:10<00:06, 11.57it/s] 64%|██████▍   | 126/196 [00:11<00:06, 11.47it/s] 65%|██████▌   | 128/196 [00:11<00:05, 11.41it/s] 66%|██████▋   | 130/196 [00:11<00:05, 11.50it/s] 67%|██████▋   | 132/196 [00:11<00:05, 11.49it/s] 68%|██████▊   | 134/196 [00:11<00:05, 11.46it/s] 69%|██████▉   | 136/196 [00:11<00:05, 11.51it/s] 70%|███████   | 138/196 [00:12<00:05, 11.48it/s] 71%|███████▏  | 140/196 [00:12<00:04, 11.44it/s]                                                  71%|███████▏  | 140/196 [00:12<00:04, 11.44it/s] 72%|███████▏  | 142/196 [00:12<00:04, 11.45it/s] 73%|███████▎  | 144/196 [00:12<00:04, 11.41it/s] 74%|███████▍  | 146/196 [00:12<00:04, 11.39it/s] 76%|███████▌  | 148/196 [00:12<00:04, 11.50it/s] 77%|███████▋  | 150/196 [00:13<00:04, 11.48it/s] 78%|███████▊  | 152/196 [00:13<00:03, 11.53it/s] 79%|███████▊  | 154/196 [00:13<00:03, 11.44it/s] 80%|███████▉  | 156/196 [00:13<00:03, 11.53it/s] 81%|████████  | 158/196 [00:13<00:03, 11.58it/s] 82%|████████▏ | 160/196 [00:13<00:03, 11.60it/s] 83%|████████▎ | 162/196 [00:14<00:02, 11.52it/s] 84%|████████▎ | 164/196 [00:14<00:02, 11.56it/s] 85%|████████▍ | 166/196 [00:14<00:02, 11.61it/s] 86%|████████▌ | 168/196 [00:14<00:02, 11.51it/s]                                                  86%|████████▌ | 168/196 [00:14<00:02, 11.51it/s] 87%|████████▋ | 170/196 [00:14<00:02, 11.54it/s] 88%|████████▊ | 172/196 [00:15<00:02, 11.57it/s] 89%|████████▉ | 174/196 [00:15<00:01, 11.41it/s] 90%|████████▉ | 176/196 [00:15<00:01, 11.41it/s] 91%|█████████ | 178/196 [00:15<00:01, 11.47it/s] 92%|█████████▏| 180/196 [00:15<00:01, 11.44it/s] 93%|█████████▎| 182/196 [00:15<00:01, 11.46it/s] 94%|█████████▍| 184/196 [00:16<00:01, 11.41it/s] 95%|█████████▍| 186/196 [00:16<00:00, 11.42it/s] 96%|█████████▌| 188/196 [00:16<00:00, 11.40it/s] 97%|█████████▋| 190/196 [00:16<00:00, 11.48it/s] 98%|█████████▊| 192/196 [00:16<00:00, 11.55it/s] 99%|█████████▉| 194/196 [00:16<00:00, 11.49it/s]100%|██████████| 196/196 [00:17<00:00, 11.53it/s]                                                 100%|██████████| 196/196 [00:17<00:00, 11.53it/s]                                                 100%|██████████| 196/196 [00:17<00:00, 11.53it/s]100%|██████████| 196/196 [00:17<00:00, 11.45it/s]
{'loss': 1.0224, 'learning_rate': 1.3000000000000001e-05, 'epoch': 1.0}
{'loss': 0.4291, 'learning_rate': 1.8205128205128208e-05, 'epoch': 2.0}
{'loss': 0.3085, 'learning_rate': 1.4615384615384615e-05, 'epoch': 3.0}
{'loss': 0.2127, 'learning_rate': 1.1025641025641028e-05, 'epoch': 4.0}
{'loss': 0.1542, 'learning_rate': 7.435897435897437e-06, 'epoch': 5.0}
{'loss': 0.1093, 'learning_rate': 3.846153846153847e-06, 'epoch': 6.0}
{'loss': 0.0778, 'learning_rate': 2.564102564102564e-07, 'epoch': 7.0}
{'train_runtime': 17.11, 'train_samples_per_second': 365.751, 'train_steps_per_second': 11.455, 'train_loss': 0.3305718874444767, 'epoch': 7.0}

Train time: 17.196702003479004 

  0%|          | 0/107 [00:00<?, ?it/s]  2%|▏         | 2/107 [00:00<00:06, 16.87it/s]  4%|▎         | 4/107 [00:00<00:09, 10.44it/s]  6%|▌         | 6/107 [00:00<00:11,  9.17it/s]  7%|▋         | 8/107 [00:00<00:11,  8.92it/s]  8%|▊         | 9/107 [00:00<00:10,  8.96it/s]  9%|▉         | 10/107 [00:01<00:10,  9.09it/s] 10%|█         | 11/107 [00:01<00:10,  9.15it/s] 11%|█         | 12/107 [00:01<00:11,  8.49it/s] 13%|█▎        | 14/107 [00:01<00:10,  8.94it/s] 14%|█▍        | 15/107 [00:01<00:10,  8.37it/s] 15%|█▍        | 16/107 [00:01<00:10,  8.60it/s] 16%|█▌        | 17/107 [00:01<00:10,  8.84it/s] 17%|█▋        | 18/107 [00:01<00:09,  9.09it/s] 18%|█▊        | 19/107 [00:02<00:09,  8.95it/s] 19%|█▊        | 20/107 [00:02<00:10,  8.56it/s] 20%|█▉        | 21/107 [00:02<00:10,  8.55it/s] 21%|██        | 22/107 [00:02<00:09,  8.83it/s] 21%|██▏       | 23/107 [00:02<00:09,  8.60it/s] 22%|██▏       | 24/107 [00:02<00:09,  8.85it/s] 23%|██▎       | 25/107 [00:02<00:09,  8.82it/s] 24%|██▍       | 26/107 [00:03<00:11,  6.92it/s] 25%|██▌       | 27/107 [00:03<00:11,  6.92it/s] 26%|██▌       | 28/107 [00:03<00:10,  7.42it/s] 27%|██▋       | 29/107 [00:03<00:09,  7.93it/s] 28%|██▊       | 30/107 [00:03<00:09,  7.99it/s] 29%|██▉       | 31/107 [00:03<00:09,  8.08it/s] 30%|██▉       | 32/107 [00:03<00:09,  8.17it/s] 31%|███       | 33/107 [00:03<00:09,  7.76it/s] 32%|███▏      | 34/107 [00:04<00:09,  7.62it/s] 33%|███▎      | 35/107 [00:04<00:09,  7.97it/s] 34%|███▎      | 36/107 [00:04<00:08,  8.14it/s] 35%|███▍      | 37/107 [00:04<00:08,  8.20it/s] 36%|███▌      | 38/107 [00:04<00:08,  8.00it/s] 36%|███▋      | 39/107 [00:04<00:08,  7.80it/s] 37%|███▋      | 40/107 [00:04<00:08,  7.48it/s] 38%|███▊      | 41/107 [00:04<00:08,  7.57it/s] 39%|███▉      | 42/107 [00:05<00:08,  7.97it/s] 40%|████      | 43/107 [00:05<00:07,  8.18it/s] 41%|████      | 44/107 [00:05<00:07,  8.24it/s] 42%|████▏     | 45/107 [00:05<00:07,  8.61it/s] 43%|████▎     | 46/107 [00:05<00:07,  8.46it/s] 44%|████▍     | 47/107 [00:05<00:07,  8.49it/s] 45%|████▍     | 48/107 [00:05<00:06,  8.62it/s] 46%|████▌     | 49/107 [00:05<00:06,  8.70it/s] 47%|████▋     | 50/107 [00:05<00:06,  8.59it/s] 48%|████▊     | 51/107 [00:06<00:06,  8.66it/s] 49%|████▊     | 52/107 [00:06<00:06,  8.93it/s] 50%|████▉     | 53/107 [00:06<00:06,  8.83it/s] 50%|█████     | 54/107 [00:06<00:05,  8.89it/s] 51%|█████▏    | 55/107 [00:06<00:06,  8.48it/s] 52%|█████▏    | 56/107 [00:06<00:06,  8.27it/s] 53%|█████▎    | 57/107 [00:06<00:06,  8.16it/s] 54%|█████▍    | 58/107 [00:06<00:06,  8.00it/s] 55%|█████▌    | 59/107 [00:07<00:05,  8.20it/s] 56%|█████▌    | 60/107 [00:07<00:05,  8.30it/s] 57%|█████▋    | 61/107 [00:07<00:05,  8.17it/s] 58%|█████▊    | 62/107 [00:07<00:05,  8.28it/s] 59%|█████▉    | 63/107 [00:07<00:05,  8.05it/s] 60%|█████▉    | 64/107 [00:07<00:05,  7.79it/s] 61%|██████    | 65/107 [00:07<00:05,  7.63it/s] 62%|██████▏   | 66/107 [00:07<00:05,  7.76it/s] 63%|██████▎   | 67/107 [00:08<00:04,  8.19it/s] 64%|██████▎   | 68/107 [00:08<00:04,  8.61it/s] 64%|██████▍   | 69/107 [00:08<00:04,  8.39it/s] 65%|██████▌   | 70/107 [00:08<00:05,  6.87it/s] 66%|██████▋   | 71/107 [00:08<00:04,  7.28it/s] 67%|██████▋   | 72/107 [00:08<00:04,  7.57it/s] 68%|██████▊   | 73/107 [00:08<00:04,  7.19it/s] 69%|██████▉   | 74/107 [00:08<00:04,  7.79it/s] 70%|███████   | 75/107 [00:09<00:03,  8.32it/s] 71%|███████   | 76/107 [00:09<00:03,  7.78it/s] 72%|███████▏  | 77/107 [00:09<00:03,  8.11it/s] 73%|███████▎  | 78/107 [00:09<00:03,  8.30it/s] 74%|███████▍  | 79/107 [00:09<00:03,  8.49it/s] 75%|███████▍  | 80/107 [00:09<00:03,  7.92it/s] 76%|███████▌  | 81/107 [00:09<00:03,  8.41it/s] 77%|███████▋  | 82/107 [00:09<00:02,  8.71it/s] 79%|███████▊  | 84/107 [00:10<00:02,  8.49it/s] 79%|███████▉  | 85/107 [00:10<00:02,  8.72it/s] 80%|████████  | 86/107 [00:10<00:02,  8.61it/s] 81%|████████▏ | 87/107 [00:10<00:02,  8.70it/s] 82%|████████▏ | 88/107 [00:10<00:02,  8.71it/s] 83%|████████▎ | 89/107 [00:10<00:02,  7.79it/s] 84%|████████▍ | 90/107 [00:10<00:02,  7.92it/s] 85%|████████▌ | 91/107 [00:11<00:02,  7.48it/s] 86%|████████▌ | 92/107 [00:11<00:01,  7.84it/s] 87%|████████▋ | 93/107 [00:11<00:01,  8.31it/s] 89%|████████▉ | 95/107 [00:11<00:01,  8.65it/s] 90%|████████▉ | 96/107 [00:11<00:01,  8.70it/s] 91%|█████████ | 97/107 [00:11<00:01,  8.68it/s] 92%|█████████▏| 98/107 [00:11<00:01,  8.73it/s] 93%|█████████▎| 99/107 [00:11<00:00,  8.32it/s] 93%|█████████▎| 100/107 [00:12<00:00,  8.15it/s] 94%|█████████▍| 101/107 [00:12<00:00,  8.16it/s] 95%|█████████▌| 102/107 [00:12<00:00,  7.87it/s] 96%|█████████▋| 103/107 [00:12<00:00,  8.21it/s] 97%|█████████▋| 104/107 [00:12<00:00,  7.88it/s] 98%|█████████▊| 105/107 [00:12<00:00,  8.28it/s] 99%|█████████▉| 106/107 [00:12<00:00,  8.46it/s]100%|██████████| 107/107 [00:12<00:00,  8.24it/s]
Highest probability prediction per premise:  [0, 2, 1, 2, 2, 3, 2, 3, 3, 1, 3, 0, 2, 0, 1, 3, 2, 1, 0, 3]
Correct labels per premise:  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]
Aggregate metrics:  {'f1_macro': 0.5490276561871567, 'f1_micro': 0.8109540636042403, 'accuracy_balanced': 0.5709476400718336, 'accuracy_not_b': 0.8109540636042403, 'precision_macro': 0.5415288593312848, 'recall_macro': 0.5709476400718336, 'precision_micro': 0.8109540636042403, 'recall_micro': 0.8109540636042403}
Detailed metrics:  {'neutral': {'precision': 0.12455516014234876, 'recall': 0.1794871794871795, 'f1-score': 0.14705882352941174, 'support': 195}, 'no_topic': {'precision': 0.925218451534241, 'recall': 0.9106, 'f1-score': 0.9178510230823506, 'support': 5000}, 'sceptical': {'precision': 0.44684129429892144, 'recall': 0.6444444444444445, 'f1-score': 0.5277525022747953, 'support': 450}, 'supportive': {'precision': 0.6695005313496281, 'recall': 0.5492589363557105, 'f1-score': 0.603448275862069, 'support': 1147}, 'accuracy': 0.8109540636042403, 'macro avg': {'precision': 0.5415288593312848, 'recall': 0.5709476400718336, 'f1-score': 0.5490276561871567, 'support': 6792}, 'weighted avg': {'precision': 0.8273522093332598, 'recall': 0.8109540636042403, 'f1-score': 0.8167808280973851, 'support': 6792}} 


Test results:
{'eval_loss': 0.4905458688735962, 'eval_f1_macro': 0.5490276561871567, 'eval_f1_micro': 0.8109540636042403, 'eval_accuracy_balanced': 0.5709476400718336, 'eval_accuracy_not_b': 0.8109540636042403, 'eval_precision_macro': 0.5415288593312848, 'eval_recall_macro': 0.5709476400718336, 'eval_precision_micro': 0.8109540636042403, 'eval_recall_micro': 0.8109540636042403, 'eval_runtime': 13.1158, 'eval_samples_per_second': 2071.397, 'eval_steps_per_second': 8.158, 'epoch': 7.0}

Script done.


