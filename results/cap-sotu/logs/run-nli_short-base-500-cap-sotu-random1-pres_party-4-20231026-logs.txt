Terminal execution:  True   (sys.argv[0]:  analysis-transformers-run.py )
Arguments passed via the terminal:

cap-sotu    dataset
500    sample_size_train
None    sample_size_corpus
20000    sample_size_no_topic
None    sample_size_test
nli_short    method
MoritzLaurer/deberta-v3-base-zeroshot-v1    model
transformer    vectorizer
20231026    study_date
cap-sotu    task
4    n_run
6    n_random_runs_total
random1    group_sample
True    save_outputs
pres_party    group_column
448    max_length
Iteration number:  3
All random seeds:  [7270  860 5390 5191 5734 6265]
Random seed for this run:  5191
deberta-v3-base-zeroshot-v
Dataset:  cap-sotu 

Overall label distribution per group member:
 pres_party                       
dem         Macroeconomics           1409
            International Affairs    1340
            Defense                  1177
            Health                    577
            Government Operations     449
rep         International Affairs    1190
            Macroeconomics           1178
            Defense                  1121
            Government Operations     439
            Health                    368
Name: label_text, dtype: int64
Group selected: ['dem']  for seed 5191
Sample that might be imbalanced: df_train.label_text.value_counts:
 Defense                  100
Government Operations    100
Health                   100
International Affairs    100
Macroeconomics           100
Name: label_text, dtype: int64

FINAL DF_TRAIN SAMPLE (BALANCED) for group \bdem\b:
df_train.label_text.value_counts:
 Defense                  100
Government Operations    100
Health                   100
International Affairs    100
Macroeconomics           100
Name: label_text, dtype: int64

For NLI: Augmenting data by adding random not_entail examples to the train set from other classes within the train set.
Length of df_train before this step is: 500.

Max augmentation can be: len(df_train) * 2 = 1000. Can also be lower, if there are more entail examples than not-entail for a majority class
For NLI:  not_entail training examples were added, which leads to an augmented training dataset of length 1000.
Number of hypotheses/classes:  5 

For normal test, N classifications necessary: 2313
For NLI test, N classifications necessary: 11565

Device: cuda
Map:   0%|          | 0/1000 [00:00<?, ? examples/s]                                                    Map:   0%|          | 0/11565 [00:00<?, ? examples/s]Map:  35%|███▍      | 4000/11565 [00:00<00:00, 30132.31 examples/s]Map:  69%|██████▉   | 8000/11565 [00:00<00:00, 30668.87 examples/s]Map: 100%|██████████| 11565/11565 [00:00<00:00, 30702.17 examples/s]                                                                      0%|          | 0/224 [00:00<?, ?it/s]You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.
  0%|          | 1/224 [00:00<00:25,  8.80it/s]  1%|          | 2/224 [00:00<00:24,  8.95it/s]  2%|▏         | 4/224 [00:00<00:21, 10.13it/s]  3%|▎         | 6/224 [00:00<00:20, 10.84it/s]  4%|▎         | 8/224 [00:00<00:19, 11.00it/s]  4%|▍         | 10/224 [00:00<00:18, 11.27it/s]  5%|▌         | 12/224 [00:01<00:18, 11.39it/s]  6%|▋         | 14/224 [00:01<00:18, 11.33it/s]  7%|▋         | 16/224 [00:01<00:18, 11.45it/s]  8%|▊         | 18/224 [00:01<00:17, 11.55it/s]  9%|▉         | 20/224 [00:01<00:17, 11.61it/s] 10%|▉         | 22/224 [00:01<00:17, 11.63it/s] 11%|█         | 24/224 [00:02<00:17, 11.66it/s] 12%|█▏        | 26/224 [00:02<00:16, 11.69it/s] 12%|█▎        | 28/224 [00:02<00:16, 11.73it/s] 13%|█▎        | 30/224 [00:02<00:16, 11.77it/s] 14%|█▍        | 32/224 [00:02<00:16, 11.65it/s]                                                 14%|█▍        | 32/224 [00:02<00:16, 11.65it/s] 15%|█▌        | 34/224 [00:02<00:16, 11.64it/s] 16%|█▌        | 36/224 [00:03<00:16, 11.67it/s] 17%|█▋        | 38/224 [00:03<00:15, 11.69it/s] 18%|█▊        | 40/224 [00:03<00:15, 11.53it/s] 19%|█▉        | 42/224 [00:03<00:15, 11.62it/s] 20%|█▉        | 44/224 [00:03<00:15, 11.67it/s] 21%|██        | 46/224 [00:04<00:15, 11.69it/s] 21%|██▏       | 48/224 [00:04<00:15, 11.55it/s] 22%|██▏       | 50/224 [00:04<00:15, 11.45it/s] 23%|██▎       | 52/224 [00:04<00:14, 11.54it/s] 24%|██▍       | 54/224 [00:04<00:14, 11.61it/s] 25%|██▌       | 56/224 [00:04<00:14, 11.51it/s] 26%|██▌       | 58/224 [00:05<00:14, 11.59it/s] 27%|██▋       | 60/224 [00:05<00:14, 11.63it/s] 28%|██▊       | 62/224 [00:05<00:13, 11.64it/s] 29%|██▊       | 64/224 [00:05<00:14, 11.37it/s]                                                 29%|██▊       | 64/224 [00:05<00:14, 11.37it/s] 29%|██▉       | 66/224 [00:05<00:13, 11.46it/s] 30%|███       | 68/224 [00:05<00:13, 11.60it/s] 31%|███▏      | 70/224 [00:06<00:13, 11.65it/s] 32%|███▏      | 72/224 [00:06<00:13, 11.68it/s] 33%|███▎      | 74/224 [00:06<00:12, 11.68it/s] 34%|███▍      | 76/224 [00:06<00:12, 11.52it/s] 35%|███▍      | 78/224 [00:06<00:12, 11.40it/s] 36%|███▌      | 80/224 [00:06<00:12, 11.46it/s] 37%|███▋      | 82/224 [00:07<00:12, 11.40it/s] 38%|███▊      | 84/224 [00:07<00:12, 11.51it/s] 38%|███▊      | 86/224 [00:07<00:11, 11.59it/s] 39%|███▉      | 88/224 [00:07<00:11, 11.64it/s] 40%|████      | 90/224 [00:07<00:11, 11.52it/s] 41%|████      | 92/224 [00:07<00:11, 11.57it/s] 42%|████▏     | 94/224 [00:08<00:11, 11.46it/s] 43%|████▎     | 96/224 [00:08<00:10, 11.65it/s]                                                 43%|████▎     | 96/224 [00:08<00:10, 11.65it/s] 44%|████▍     | 98/224 [00:08<00:10, 11.51it/s] 45%|████▍     | 100/224 [00:08<00:10, 11.44it/s] 46%|████▌     | 102/224 [00:08<00:10, 11.53it/s] 46%|████▋     | 104/224 [00:09<00:10, 11.60it/s] 47%|████▋     | 106/224 [00:09<00:10, 11.62it/s] 48%|████▊     | 108/224 [00:09<00:09, 11.66it/s] 49%|████▉     | 110/224 [00:09<00:09, 11.63it/s] 50%|█████     | 112/224 [00:09<00:09, 11.66it/s] 51%|█████     | 114/224 [00:09<00:09, 11.52it/s] 52%|█████▏    | 116/224 [00:10<00:09, 11.59it/s] 53%|█████▎    | 118/224 [00:10<00:09, 11.62it/s] 54%|█████▎    | 120/224 [00:10<00:09, 11.49it/s] 54%|█████▍    | 122/224 [00:10<00:08, 11.56it/s] 55%|█████▌    | 124/224 [00:10<00:08, 11.64it/s] 56%|█████▋    | 126/224 [00:10<00:08, 11.51it/s] 57%|█████▋    | 128/224 [00:11<00:08, 11.67it/s]                                                  57%|█████▋    | 128/224 [00:11<00:08, 11.67it/s] 58%|█████▊    | 130/224 [00:11<00:08, 11.65it/s] 59%|█████▉    | 132/224 [00:11<00:08, 11.49it/s] 60%|█████▉    | 134/224 [00:11<00:07, 11.57it/s] 61%|██████    | 136/224 [00:11<00:07, 11.62it/s] 62%|██████▏   | 138/224 [00:11<00:07, 11.66it/s] 62%|██████▎   | 140/224 [00:12<00:07, 11.69it/s] 63%|██████▎   | 142/224 [00:12<00:07, 11.69it/s] 64%|██████▍   | 144/224 [00:12<00:06, 11.70it/s] 65%|██████▌   | 146/224 [00:12<00:06, 11.71it/s] 66%|██████▌   | 148/224 [00:12<00:06, 11.57it/s] 67%|██████▋   | 150/224 [00:13<00:06, 11.60it/s] 68%|██████▊   | 152/224 [00:13<00:06, 11.65it/s] 69%|██████▉   | 154/224 [00:13<00:05, 11.69it/s] 70%|██████▉   | 156/224 [00:13<00:05, 11.70it/s] 71%|███████   | 158/224 [00:13<00:05, 11.39it/s] 71%|███████▏  | 160/224 [00:13<00:05, 11.63it/s]                                                  71%|███████▏  | 160/224 [00:13<00:05, 11.63it/s] 72%|███████▏  | 162/224 [00:14<00:05, 11.69it/s] 73%|███████▎  | 164/224 [00:14<00:05, 11.73it/s] 74%|███████▍  | 166/224 [00:14<00:05, 11.56it/s] 75%|███████▌  | 168/224 [00:14<00:04, 11.68it/s] 76%|███████▌  | 170/224 [00:14<00:04, 11.54it/s] 77%|███████▋  | 172/224 [00:14<00:04, 11.63it/s] 78%|███████▊  | 174/224 [00:15<00:04, 11.67it/s] 79%|███████▊  | 176/224 [00:15<00:04, 11.70it/s] 79%|███████▉  | 178/224 [00:15<00:03, 11.70it/s] 80%|████████  | 180/224 [00:15<00:03, 11.72it/s] 81%|████████▏ | 182/224 [00:15<00:03, 11.74it/s] 82%|████████▏ | 184/224 [00:15<00:03, 11.55it/s] 83%|████████▎ | 186/224 [00:16<00:03, 11.62it/s] 84%|████████▍ | 188/224 [00:16<00:03, 11.47it/s] 85%|████████▍ | 190/224 [00:16<00:02, 11.56it/s] 86%|████████▌ | 192/224 [00:16<00:02, 11.52it/s]                                                  86%|████████▌ | 192/224 [00:16<00:02, 11.52it/s] 87%|████████▋ | 194/224 [00:16<00:02, 11.59it/s] 88%|████████▊ | 196/224 [00:16<00:02, 11.72it/s] 88%|████████▊ | 198/224 [00:17<00:02, 11.57it/s] 89%|████████▉ | 200/224 [00:17<00:02, 11.49it/s] 90%|█████████ | 202/224 [00:17<00:01, 11.56it/s] 91%|█████████ | 204/224 [00:17<00:01, 11.62it/s] 92%|█████████▏| 206/224 [00:17<00:01, 11.67it/s] 93%|█████████▎| 208/224 [00:17<00:01, 11.68it/s] 94%|█████████▍| 210/224 [00:18<00:01, 11.55it/s] 95%|█████████▍| 212/224 [00:18<00:01, 11.62it/s] 96%|█████████▌| 214/224 [00:18<00:00, 11.66it/s] 96%|█████████▋| 216/224 [00:18<00:00, 11.50it/s] 97%|█████████▋| 218/224 [00:18<00:00, 11.55it/s] 98%|█████████▊| 220/224 [00:19<00:00, 11.62it/s] 99%|█████████▉| 222/224 [00:19<00:00, 11.48it/s]100%|██████████| 224/224 [00:19<00:00, 11.69it/s]                                                 100%|██████████| 224/224 [00:19<00:00, 11.69it/s]                                                 100%|██████████| 224/224 [00:19<00:00, 11.69it/s]100%|██████████| 224/224 [00:19<00:00, 11.56it/s]
{'loss': 0.7665, 'learning_rate': 1.377777777777778e-05, 'epoch': 1.0}
{'loss': 0.3463, 'learning_rate': 1.798882681564246e-05, 'epoch': 2.0}
{'loss': 0.2309, 'learning_rate': 1.4413407821229052e-05, 'epoch': 3.0}
{'loss': 0.1601, 'learning_rate': 1.0837988826815644e-05, 'epoch': 4.0}
{'loss': 0.0833, 'learning_rate': 7.262569832402235e-06, 'epoch': 5.0}
{'loss': 0.0666, 'learning_rate': 3.687150837988827e-06, 'epoch': 6.0}
{'loss': 0.0511, 'learning_rate': 1.11731843575419e-07, 'epoch': 7.0}
{'train_runtime': 19.3705, 'train_samples_per_second': 361.374, 'train_steps_per_second': 11.564, 'train_loss': 0.24355061831218855, 'epoch': 7.0}

Train time: 19.456631422042847 

  0%|          | 0/46 [00:00<?, ?it/s]  4%|▍         | 2/46 [00:00<00:03, 12.54it/s]  9%|▊         | 4/46 [00:00<00:04,  9.99it/s] 13%|█▎        | 6/46 [00:00<00:04,  9.90it/s] 17%|█▋        | 8/46 [00:00<00:03,  9.62it/s] 20%|█▉        | 9/46 [00:00<00:03,  9.51it/s] 22%|██▏       | 10/46 [00:01<00:03,  9.41it/s] 24%|██▍       | 11/46 [00:01<00:03,  9.35it/s] 26%|██▌       | 12/46 [00:01<00:03,  9.12it/s] 28%|██▊       | 13/46 [00:01<00:03,  8.92it/s] 30%|███       | 14/46 [00:01<00:03,  8.77it/s] 33%|███▎      | 15/46 [00:01<00:03,  8.43it/s] 35%|███▍      | 16/46 [00:01<00:03,  7.52it/s] 37%|███▋      | 17/46 [00:01<00:04,  7.03it/s] 39%|███▉      | 18/46 [00:02<00:03,  7.24it/s] 41%|████▏     | 19/46 [00:02<00:03,  7.80it/s] 43%|████▎     | 20/46 [00:02<00:03,  7.46it/s] 46%|████▌     | 21/46 [00:02<00:03,  7.87it/s] 50%|█████     | 23/46 [00:02<00:02,  8.75it/s] 52%|█████▏    | 24/46 [00:02<00:02,  8.82it/s] 54%|█████▍    | 25/46 [00:02<00:02,  8.95it/s] 57%|█████▋    | 26/46 [00:02<00:02,  8.93it/s] 59%|█████▊    | 27/46 [00:03<00:02,  8.94it/s] 61%|██████    | 28/46 [00:03<00:02,  8.37it/s] 63%|██████▎   | 29/46 [00:03<00:01,  8.71it/s] 65%|██████▌   | 30/46 [00:03<00:01,  8.46it/s] 67%|██████▋   | 31/46 [00:03<00:01,  8.73it/s] 70%|██████▉   | 32/46 [00:03<00:01,  8.62it/s] 72%|███████▏  | 33/46 [00:03<00:01,  8.64it/s] 74%|███████▍  | 34/46 [00:03<00:01,  8.54it/s] 76%|███████▌  | 35/46 [00:04<00:01,  8.78it/s] 78%|███████▊  | 36/46 [00:04<00:01,  8.57it/s] 80%|████████  | 37/46 [00:04<00:01,  8.73it/s] 83%|████████▎ | 38/46 [00:04<00:00,  9.04it/s] 85%|████████▍ | 39/46 [00:04<00:00,  9.13it/s] 87%|████████▋ | 40/46 [00:04<00:00,  8.47it/s] 89%|████████▉ | 41/46 [00:04<00:00,  8.70it/s] 91%|█████████▏| 42/46 [00:04<00:00,  8.39it/s] 93%|█████████▎| 43/46 [00:04<00:00,  7.98it/s] 96%|█████████▌| 44/46 [00:05<00:00,  8.39it/s]100%|██████████| 46/46 [00:05<00:00, 10.84it/s]100%|██████████| 46/46 [00:05<00:00,  8.72it/s]
Highest probability prediction per premise:  [0, 2, 0, 0, 3, 3, 4, 0, 0, 4, 1, 3, 0, 3, 4, 2, 4, 0, 4, 2]
Correct labels per premise:  [0, 2, 0, 0, 0, 3, 4, 3, 3, 4, 1, 3, 3, 0, 4, 2, 4, 0, 4, 4]
Aggregate metrics:  {'f1_macro': 0.7206308060662853, 'f1_micro': 0.7207090358841332, 'accuracy_balanced': 0.7351496658674311, 'accuracy_not_b': 0.7207090358841332, 'precision_macro': 0.7141079336421856, 'recall_macro': 0.7351496658674311, 'precision_micro': 0.7207090358841332, 'recall_micro': 0.7207090358841332}
Detailed metrics:  {'Defense': {'precision': 0.6945996275605214, 'recall': 0.648695652173913, 'f1-score': 0.6708633093525179, 'support': 575}, 'Government Operations': {'precision': 0.5625, 'recall': 0.7702702702702703, 'f1-score': 0.6501901140684411, 'support': 222}, 'Health': {'precision': 0.7833333333333333, 'recall': 0.7966101694915254, 'f1-score': 0.7899159663865546, 'support': 236}, 'International Affairs': {'precision': 0.6707317073170732, 'recall': 0.6951026856240127, 'f1-score': 0.6826997672614431, 'support': 633}, 'Macroeconomics': {'precision': 0.859375, 'recall': 0.7650695517774343, 'f1-score': 0.8094848732624693, 'support': 647}, 'accuracy': 0.7207090358841332, 'macro avg': {'precision': 0.7141079336421856, 'recall': 0.7351496658674311, 'f1-score': 0.7206308060662853, 'support': 2313}, 'weighted avg': {'precision': 0.7305340459341435, 'recall': 0.7207090358841332, 'f1-score': 0.72304126327083, 'support': 2313}} 


Test results:
{'eval_loss': 0.9677655696868896, 'eval_f1_macro': 0.7206308060662853, 'eval_f1_micro': 0.7207090358841332, 'eval_accuracy_balanced': 0.7351496658674311, 'eval_accuracy_not_b': 0.7207090358841332, 'eval_precision_macro': 0.7141079336421856, 'eval_recall_macro': 0.7351496658674311, 'eval_precision_micro': 0.7207090358841332, 'eval_recall_micro': 0.7207090358841332, 'eval_runtime': 5.3833, 'eval_samples_per_second': 2148.291, 'eval_steps_per_second': 8.545, 'epoch': 7.0}

Script done.


