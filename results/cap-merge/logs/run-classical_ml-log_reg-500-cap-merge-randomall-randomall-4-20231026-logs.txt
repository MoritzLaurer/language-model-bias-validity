Terminal execution:  True   (sys.argv[0]:  analysis-classical-run.py )
Arguments passed via the terminal:

cap-merge    dataset
500    sample_size_train
None    sample_size_corpus
20000    sample_size_no_topic
None    sample_size_test
classical_ml    method
log_reg    model
tfidf    vectorizer
20231026    study_date
cap-merge    task
4    n_run
6    n_random_runs_total
randomall    group_sample
True    save_outputs
randomall    group_column
448    max_length
Iteration number:  3
All random seeds:  [7270  860 5390 5191 5734 6265]
Random seed for this run:  5191
log_reg
Dataset:  cap-merge 

Overall label distribution per group member:
 No group used. Sampling with randomall.
GROUP_SAMPLE is randomall, so just sampling from entire corpus without group selection
Sample that might be imbalanced: df_train.label_text.value_counts:
 Civil Rights             100
Domestic Commerce        100
Government Operations    100
Labor                    100
Law and Crime            100
Name: label_text, dtype: int64

FINAL DF_TRAIN SAMPLE (BALANCED) for group randomall:
df_train.label_text.value_counts:
 Civil Rights             100
Domestic Commerce        100
Government Operations    100
Labor                    100
Law and Crime            100
Name: label_text, dtype: int64
Spacy lemmatization done

Train time: 0.17172718048095703 

Aggregate metrics:  {'eval_f1_macro': 0.6060396575473108, 'eval_f1_micro': 0.6141078838174274, 'eval_accuracy_balanced': 0.6140419676971189, 'eval_accuracy_not_b': 0.6141078838174274, 'eval_precision_macro': 0.6019434978987368, 'eval_recall_macro': 0.6140419676971189, 'eval_precision_micro': 0.6141078838174274, 'eval_recall_micro': 0.6141078838174274}
Detailed metrics:  {'Civil Rights': {'precision': 0.46115288220551376, 'recall': 0.5333333333333333, 'f1-score': 0.4946236559139785, 'support': 345}, 'Domestic Commerce': {'precision': 0.6271186440677966, 'recall': 0.6776556776556777, 'f1-score': 0.6514084507042254, 'support': 273}, 'Government Operations': {'precision': 0.5102639296187683, 'recall': 0.5209580838323353, 'f1-score': 0.5155555555555555, 'support': 334}, 'Labor': {'precision': 0.655786350148368, 'recall': 0.7038216560509554, 'f1-score': 0.6789554531490015, 'support': 314}, 'Law and Crime': {'precision': 0.7553956834532374, 'recall': 0.6344410876132931, 'f1-score': 0.6896551724137931, 'support': 662}, 'accuracy': 0.6141078838174274, 'macro avg': {'precision': 0.6019434978987368, 'recall': 0.6140419676971189, 'f1-score': 0.6060396575473108, 'support': 1928}, 'weighted avg': {'precision': 0.6258911530480861, 'recall': 0.6141078838174274, 'f1-score': 0.617437220080316, 'support': 1928}} 


Test results:
{'eval_f1_macro': 0.6060396575473108, 'eval_f1_micro': 0.6141078838174274, 'eval_accuracy_balanced': 0.6140419676971189, 'eval_accuracy_not_b': 0.6141078838174274, 'eval_precision_macro': 0.6019434978987368, 'eval_recall_macro': 0.6140419676971189, 'eval_precision_micro': 0.6141078838174274, 'eval_recall_micro': 0.6141078838174274}

Script done.


